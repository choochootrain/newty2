{
 "metadata": {
  "name": "apple_data_mining"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Sentiment analysis adapted from basic_sentiment_analysis.py and trends.py\n",
      "'''\n",
      "import numpy as np\n",
      "import math\n",
      "from pprint import pprint\n",
      "from data import word_sentiments # word_sentiments is a dictionary of words with a sentiment between -1 (negative) to 1 (positive)\n",
      "import nltk\n",
      "import os\n",
      "import re\n",
      "from collections import Counter\n",
      "from pandas import DataFrame\n",
      "import datetime as DT\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib.dates import date2num\n",
      "\n",
      "f = open('articles/techcrunch_articles.csv', 'rb')\n",
      "tc_data = DataFrame.from_csv(f, header=0)\n",
      "\n",
      "regex = re.compile('            Learn more  End of panel-container -->')\n",
      "\n",
      "\n",
      "def clean_words(text):\n",
      "    '''Cleans corpus up, removing HTML and punctuation.'''\n",
      "    cleaned_text = regex.sub('', text)\n",
      "    return cleaned_text\n",
      "\n",
      "\n",
      "def bag_of_words(words):\n",
      "    return Counter(words.split())\n",
      "\n",
      "\n",
      "def extract_article_sentiment(cleaned_text):\n",
      "    # Step 1: Create Bag of Words\n",
      "    bag = bag_of_words(cleaned_text)\n",
      "    # Step 2: Update Sentiment\n",
      "    sentiment = 0\n",
      "    for word in bag:\n",
      "        if word in word_sentiments.keys():\n",
      "            sentiment += word_sentiments[word] * bag[word] # creates weighted sum of sentiment, based upon the nubmer of times that word appeared.\n",
      "    return sentiment / sum(bag.values())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == '__main__':\n",
      "    articles = tc_data['body']\n",
      "    data = dict()\n",
      "    sentiments = []\n",
      "    dates = []\n",
      "    for article, index in zip(articles, tc_data.index):\n",
      "        if article == article:\n",
      "            cleaned_article = clean_words(article)\n",
      "            sentiment = extract_article_sentiment(cleaned_article)\n",
      "            data[index] = sentiment\n",
      "            ## Getting the dates\n",
      "            link = index.split('/') #\n",
      "            dates.append(date2num(DT.datetime.strptime(link[3] + link[4] + link[5], '%Y%m%d')))\n",
      "            sentiments.append(sentiment)\n",
      "    plt.scatter(dates, sentiments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-2-502e06f73e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0marticle\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0marticle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mcleaned_article\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclean_words\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_article_sentiment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcleaned_article\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentiment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0;31m## Getting the dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m<ipython-input-1-9d1ac4d20011>\u001b[0m in \u001b[0;36mextract_article_sentiment\u001b[0;34m(cleaned_text)\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0msentiment\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbag\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_sentiments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0msentiment\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mword_sentiments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbag\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# creates weighted sum of sentiment, based upon the nubmer of times that word appeared.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0msentiment\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbag\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_sent = sorted(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sorted_sent[0]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}