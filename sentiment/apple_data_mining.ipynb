{
 "metadata": {
  "name": "apple_data_mining"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "'''\n",
      "Sentiment analysis adapted from basic_sentiment_analysis.py and trends.py\n",
      "'''\n",
      "import numpy as np\n",
      "import math\n",
      "from pprint import pprint\n",
      "from data import word_sentiments # word_sentiments is a dictionary of words with a sentiment between -1 (negative) to 1 (positive)\n",
      "import nltk\n",
      "import os\n",
      "import re\n",
      "from collections import Counter\n",
      "from pandas import DataFrame\n",
      "import datetime as DT\n",
      "from matplotlib import pyplot as plt\n",
      "from matplotlib.dates import date2num\n",
      "\n",
      "f = open('articles/techcrunch_articles.csv', 'rb')\n",
      "tc_data = DataFrame.from_csv(f, header=0)\n",
      "\n",
      "regex = re.compile('            Learn more  End of panel-container -->')\n",
      "\n",
      "\n",
      "def clean_words(text):\n",
      "    '''Cleans corpus up, removing HTML and punctuation.'''\n",
      "    cleaned_text = regex.sub('', text)\n",
      "    return cleaned_text\n",
      "\n",
      "\n",
      "def bag_of_words(words):\n",
      "    return Counter(words.split())\n",
      "\n",
      "\n",
      "def extract_article_sentiment(cleaned_text):\n",
      "    # Step 1: Create Bag of Words\n",
      "    bag = bag_of_words(cleaned_text)\n",
      "    # Step 2: Update Sentiment\n",
      "    sentiment = 0\n",
      "    for word in bag:\n",
      "        if word in word_sentiments.keys():\n",
      "            sentiment += word_sentiments[word] * bag[word] # creates weighted sum of sentiment, based upon the nubmer of times that word appeared.\n",
      "    return sentiment / sum(bag.values())\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "if __name__ == '__main__':\n",
      "    articles = tc_data['body']\n",
      "    data = dict()\n",
      "    x = []\n",
      "    y = []\n",
      "    for article, index in zip(articles, tc_data.index):\n",
      "        if article == article:\n",
      "            cleaned_article = clean_words(article)\n",
      "            sentiment = extract_article_sentiment(cleaned_article)\n",
      "            data[index] = sentiment\n",
      "            ## Getting the dates\n",
      "            link = index.split('/') #\n",
      "            x.append(date2num(DT.datetime.strptime(link[3] + link[4] + link[5], '%Y%m%d')))\n",
      "            y.append(sentiment)\n",
      "    plt.scatter(x, y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": "*"
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "False"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}